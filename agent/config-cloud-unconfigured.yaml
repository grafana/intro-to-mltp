server:
  log_level: debug

# Configures a metrics scraping service, used to scrape metrics and send
# to Grafana Cloud Metrics.
metrics:
  global:
    scrape_interval: 15s # By default, scrape targets every 15 seconds.
    # Remote write to the Grafana Cloud Metrics.
    remote_write:
      - url: ${GRAFANA_METRICS_WRITE_URL}
        basic_auth:
          username: ${GRAFANA_METRICS_USERNAME}
          password: ${GRAFANA_METRICS_API_KEY}
        send_exemplars: true

  # Define a set of configurations for scraping by Grafana Agent.
  configs:
    - name: mimir
      # The `scrape_configs` section pertains to the Prometheus `scrape_configs`
      # configuration block.
      # See https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
      scrape_configs:

        # Scrape from the Mythical Server service.
        - job_name: 'mythical-server'
          scrape_interval: 2s
          static_configs:
            - targets: ['mythical-server:4000']
              labels:
                service: 'mythical-server'
                group: 'mythical'

        # Scrape from the Mythical Requester service.
        - job_name: 'mythical-requester'
          scrape_interval: 2s
          static_configs:
            - targets: ['mythical-requester:4001']
              labels:
                service: 'mythical-requester'
                group: 'mythical'

        # Scrape from Grafana Agent, giving us metrics from trace spans it collects.
        # Not required if Grafana Cloud Trace Metrics are enabled.
        - job_name: 'span-metrics'
          scrape_interval: 2s
          static_configs:
            - targets: ['agent:12348']
              labels:
                group: 'mythical'

# Enable integrations.
# All metrics scraped from these integrations will use the `remote_write` block
# in the `global` configuration, above.
integrations:
  # Scrape metrics data from the Agent itself.
  agent:
    enabled: true
  # Scrape metrics data from the in-built Node Exporter instance.
  node_exporter:
    enabled: true

# Configures a log ingestion endpoint. This is used for the autologging feature in the tracing configuration below.
logs:
  # Define a single Promtail (logs) instance.
  # See https://grafana.com/docs/loki/latest/clients/promtail/
  configs:
    # Create a Promtail instance named `loki`, that pushes all log data to Grafana Cloud Logs and
    # adds an external label for the job.
    - name: loki
      clients:
        - url: ${GRAFANA_LOGS_WRITE_URL}
          basic_auth:
            username: ${GRAFANA_LOGS_USERNAME}
            password: ${GRAFANA_LOGS_API_KEY}
          external_labels:
            job: agent
  positions_directory: /tmp/positions

# Configure trace receiving.
traces:
  # Define a single trace configuration (each being a Tempo instance), named `tempo`.
  configs:
    - name: tempo
      # Add a custom attribute to every received span. This processor follows the conventions for the OpenTelemetry
      # collector attribute processor.
      # See https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/attributesprocessor/README.md
      attributes:
        actions:
          - key: custom.attribute
            action: upsert
            value: some-value
      # Define the protocols to receive traces in. In this case, OTLP gRPC on the default port (4317).
      # See https://grafana.com/docs/agent/latest/configuration/traces-config/ receivers.
      receivers:
        otlp:
          protocols:
            grpc:
      # Generate logs automatically from incoming trace data.
      automatic_logging:
        # Use the logs instance defined at the start of the configuration file, specifying a logs instance and the
        # named Promtail instance.
        backend: logs_instance
        logs_instance_name: loki
        # Ensure one log one line per root span (ie. one per trace).
        roots: true
        processes: false
        # Setting spans to `true` (default false) will generate a log line *per span* received. Note that this
        # can produce a huge amount of log information.
        spans: false
        # If present in the span, add the http.method, http.target and http.status_code span attributes to the log line.
        span_attributes:
          - http.method
          - http.target
          - http.status_code
        # Force the trace ID to be set as `traceId`. This ensures correlation from within Grafana between data sources.
        overrides:
          trace_id_key: "traceId"
      # Send batched traces to Grafana Cloud Traces.
      remote_write:
        - basic_auth:
            username: ${GRAFANA_TRACES_USERNAME}
            password: ${GRAFANA_TRACES_API_KEY}
          endpoint: ${GRAFANA_TRACES_HOST}
          sending_queue:
            enabled: true
            num_consumers: 20
            queue_size: 50000

      # Generate Prometheus metrics from the incoming trace spans.
      spanmetrics:
        # Add the http.target, http.method and http.status_code span attributes as labels for the metrics data.
        dimensions:
          - name: http.method
          - name: http.target
          - name: http.status_code
          - name: service.version
        # Expose these metrics on port 12348 for Grafana Agent to scrape.
        handler_endpoint: 0.0.0.0:12348
      # Enable service graphs for visual representation of services within Grafana.
      service_graphs:
        enabled: true
