name: grafana-intro-to-mltp
volumes:
  grafana:
  postgres:
services:
  # Grafana Alloy batches and processes traces sent to it, generating
  # auto-logs from those traces.
  # Includes Metrics, Logs, Traces and Profiles.
  alloy:
    image: grafana/alloy:v1.9.1
    ports:
      - "12350:12350"
      - "12347:12345"
      - "12348:12348"
      - "6832:6832"
      - "55679:55679"
      - "4317:4317"
      - "4318:4318"
    volumes:
      - "./alloy/config.alloy:/etc/alloy/config.alloy"
      - "./alloy/endpoints.json:/etc/alloy/endpoints.json"
    command: [
      "run",
      "--server.http.listen-addr=0.0.0.0:12345",
      "--stability.level=public-preview",
      "/etc/alloy/config.alloy",
    ]

  # The Grafana dashboarding server.
  grafana:
    image: grafana/grafana:12.0.2
    volumes:
      - "./grafana/definitions:/var/lib/grafana/dashboards"
      - "./grafana/provisioning:/etc/grafana/provisioning"
    ports:
      - "3000:3000"
    environment:
      - GF_FEATURE_TOGGLES_ENABLE=flameGraph traceqlSearch traceQLStreaming correlations metricsSummary traceqlEditor traceToMetrics traceToProfiles datatrails
      - GF_INSTALL_PLUGINS=grafana-lokiexplore-app,grafana-exploretraces-app,grafana-pyroscope-app
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true

  # A RabbitMQ queue used to send message between the requester and the server microservices.
  mythical-queue:
    image: rabbitmq:management
    restart: always
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: rabbitmq-diagnostics check_running
      interval: 5s
      timeout: 30s
      retries: 10

  # A postgres DB used to store data by the API server microservice.
  mythical-database:
    image: postgres:14.5
    restart: always
    environment:
      POSTGRES_PASSWORD: "mythical"
    volumes:
      - "postgres:/var/lib/postgresql/data"
    ports:
      - "5432:5432"

  # A microservice that makes requests to the API server microservice. Requests are also pushed onto the mythical-queue.
  mythical-requester:
    #build:
    #  context: ./source
    #  dockerfile: docker/Dockerfile
    #  args:
    #    SERVICE: mythical-beasts-requester
    image: grafana/intro-to-mltp:mythical-beasts-requester-latest
    restart: always
    depends_on:
      mythical-queue:
        condition: service_healthy
      mythical-server:
        condition: service_started
    ports:
      - "4001:4001"
    environment:
      - NAMESPACE=production
      - LOGS_TARGET=http://alloy:3100/loki/api/v1/push
      - TRACING_COLLECTOR_HOST=alloy
      - TRACING_COLLECTOR_PORT=4317
      - PROFILE_COLLECTOR_HOST=alloy
      - PROFILE_COLLECTOR_PORT=4040
      - OTEL_EXPORTER_OTLP_TRACES_INSECURE=true
      - OTEL_RESOURCE_ATTRIBUTES=ip=1.2.3.4
      # Uncomment this line to enable timeshift example in the mythical-requester service, which will use timestamps
      # in the log lines themselves to rewrite the default timestamp to the time specified in the logline.
      #- TIMESHIFT=true

  # The API server microservice.
  # It writes logs directly to the Loki service, exposes metrics for the Prometheus
  # service and sends traces to the Grafana Alloy instance.
  mythical-server:
    #build:
    #  context: ./source
    #  dockerfile: docker/Dockerfile
    #  args:
    #    SERVICE: mythical-beasts-server
    image: grafana/intro-to-mltp:mythical-beasts-server-latest
    restart: always
    ports:
      - "4000:4000"
      - "80:80"
    depends_on:
      - mythical-database
    environment:
      - NAMESPACE=production
      - LOGS_TARGET=http://alloy:3100/loki/api/v1/push
      - TRACING_COLLECTOR_HOST=alloy
      - TRACING_COLLECTOR_PORT=4317
      - PROFILE_COLLECTOR_HOST=alloy
      - PROFILE_COLLECTOR_PORT=4040
      - OTEL_EXPORTER_OTLP_TRACES_INSECURE=true
      - OTEL_RESOURCE_ATTRIBUTES=ip=1.2.3.5
      # Faro configuration for the frontend, sends to the local Alloy instance.
      # You can change this to send to Grafana Cloud, but see the `docker-compose-cloud.yml` compose file instead
      # to send all data to Grafana Cloud.
      - FARO_ENDPOINT=http://localhost:12350/collect
      - USE_GRAFANA_CLOUD=false

  # A microservice that consumes requests from the mythical-queue
  mythical-recorder:
    #build:
    #  context: ./source
    #  dockerfile: docker/Dockerfile
    #  args:
    #    SERVICE: mythical-beasts-recorder
    image: grafana/intro-to-mltp:mythical-beasts-recorder-latest
    restart: always
    depends_on:
      mythical-queue:
        condition: service_healthy
    ports:
      - "4002:4002"
    environment:
      - NAMESPACE=production
      - LOGS_TARGET=http://alloy:3100/loki/api/v1/push
      - TRACING_COLLECTOR_HOST=alloy
      - TRACING_COLLECTOR_PORT=4317
      - PROFILE_COLLECTOR_HOST=alloy
      - PROFILE_COLLECTOR_PORT=4040
      - OTEL_EXPORTER_OTLP_TRACES_INSECURE=true
      - OTEL_RESOURCE_ATTRIBUTES=ip=1.2.3.5

  # React frontend for the mythical beasts management system
  mythical-frontend:
    #build:
    #  context: ./source/mythical-beasts-frontend
    #  dockerfile: Dockerfile
    #  args:
    #    - REACT_APP_API_URL=/api
    image: grafana/intro-to-mltp:mythical-beasts-frontend-latest
    restart: always
    depends_on:
      mythical-server:
        condition: service_started
      alloy:
        condition: service_started
    ports:
      - "3001:80"

  # The Tempo service stores traces send to it by Grafana Alloy, and takes
  # queries from Grafana to visualise those traces.
  tempo:
    image: grafana/tempo:2.8.1
    ports:
      - "3200:3200"
      - "9411:9411"
      - "55680:55680"
      - "55681:55681"
      - "14250:14250"
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - "./tempo/tempo.yaml:/etc/tempo.yaml"

  # The Loki service stores logs sent to it, and takes queries from Grafana
  # to visualise those logs.
  loki:
    image: grafana/loki:3.5.1
    command: ["--pattern-ingester.enabled=true", "-config.file=/etc/loki/loki.yaml"]
    ports:
      - "3100:3100"
    volumes:
      - "./loki/loki.yaml:/etc/loki/loki.yaml"

  mimir:
    image: grafana/mimir:2.16.0
    command: ["-ingester.native-histograms-ingestion-enabled=true", "-config.file=/etc/mimir.yaml"]
    ports:
      - "9009:9009"
    volumes:
      - "./mimir/mimir.yaml:/etc/mimir.yaml"

  k6:
    image: grafana/k6:0.58.0
    volumes:
      - "./k6:/scripts"
    environment:
      - K6_PROMETHEUS_RW_SERVER_URL=http://mimir:9009/api/v1/push
      - K6_DURATION=3600s
      - K6_VUS=4
      - K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM=true
    restart: always
    command: ["run", "-o", "experimental-prometheus-rw", "/scripts/mythical-loadtest.js"]

  pyroscope:
    image: grafana/pyroscope:1.13.5
    ports:
      - "4040:4040"
    command: ["server"]

  beyla-requester:
    image: grafana/beyla:2.1.0
    # Beyla requires to be run in the same process namespace as the process it's watching.
    # In Docker, we can do this by joining the namespace for the watched process with the Beyla
    # container watching it by using a specific `pid` label.
    pid: "service:mythical-requester"
    # Beyla requires the several system capabilities to run, to add hooks to the underlying kernel.
    # Note that you should *always* be aware of the security implications of adding capabilities
    # before you do so.
    cap_add:
      - SYS_ADMIN
      - SYS_RESOURCE
      - NET_RAW
      - DAC_READ_SEARCH
      - SYS_PTRACE
      - PERFMON
      - BPF
      - CHECKPOINT_RESTORE
    # If using the above capability fails to instrument your service, remove it and uncomment the
    # line below. Beware that this will allow Beyla to run with full privileges, which may be
    # undesirable.
    #privileged: true
    command:
      - /beyla
      - --config=/configs/config.yaml
    volumes:
      - ./beyla/:/configs
    # See the full list of configuration options at
    # https://grafana.com/docs/grafana-cloud/monitor-applications/beyla/configure/options/ for more details on the
    # options set below.
    environment:
      BEYLA_OPEN_PORT: "4001"                                   # Instrument any service listening on port 4001.
      BEYLA_SERVICE_NAMESPACE: "mythical"                       # The namespace for the service.
      BEYLA_PROMETHEUS_PORT: "9090"                             # The port to expose Prometheus metrics on.
      #BEYLA_BPF_TRACK_REQUEST_HEADERS: "true"
      OTEL_SERVICE_NAME: "beyla-mythical-requester"             # The service name to use for OpenTelemetry traces.
      OTEL_EXPORTER_OTLP_TRACES_INSECURE: "true"                # Whether to use an insecure connection to Grafana Alloy.
      OTEL_EXPORTER_OTLP_PROTOCOL: "grpc"                       # The protocol to use to send traces to Grafana Alloy.
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "http://alloy:4317"   # The endpoint to send traces to.
    # The `depends_on` block below ensures that the mythical-requester service is started before Beyla.
    depends_on:
      mythical-requester:
        condition: service_started

  beyla-server:
    image: grafana/beyla:2.1.0
    # Beyla requires to be run in the same process namespace as the process it's watching.
    # In Docker, we can do this by joining the namespace for the watched process with the Beyla
    # container watching it by using a specific `pid` label.
    pid: "service:mythical-server"
    # Beyla requires the several system capabilities to run, to add hooks to the underlying kernel.
    # Note that you should *always* be aware of the security implications of adding capabilities
    # before you do so.
    cap_add:
      - SYS_ADMIN
      - SYS_RESOURCE
      - NET_RAW
      - DAC_READ_SEARCH
      - SYS_PTRACE
      - PERFMON
      - BPF
      - CHECKPOINT_RESTORE
    # If using the above capability fails to instrument your service, remove it and uncomment the
    # line below. Beware that this will allow Beyla to run with full privileges, which may be
    # undesirable.
    #privileged: true
    command:
      - /beyla
      - --config=/configs/config.yaml
    volumes:
      - ./beyla/:/configs
    # See the full list of configuration options at
    # https://grafana.com/docs/grafana-cloud/monitor-applications/beyla/configure/options/ for more details on the
    # options set below.
    environment:
      BEYLA_OPEN_PORT: "4000"                                   # Instrument any service listening on port 4000.
      BEYLA_SERVICE_NAMESPACE: "mythical"                       # The namespace for the service.
      BEYLA_PROMETHEUS_PORT: "9090"                             # The port to expose Prometheus metrics on.
      #BEYLA_BPF_TRACK_REQUEST_HEADERS: "true"
      OTEL_SERVICE_NAME: "beyla-mythical-server"                # The service name to use for OpenTelemetry traces.
      OTEL_EXPORTER_OTLP_TRACES_INSECURE: "true"                # Whether to use an insecure connection to Grafana Alloy.
      OTEL_EXPORTER_OTLP_PROTOCOL: "grpc"                       # The protocol to use to send traces to Grafana Alloy.
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "http://alloy:4317"   # The endpoint to send traces to.
    # The `depends_on` block below ensures that the mythical-server service is started before Beyla.
    depends_on:
      mythical-server:
        condition: service_started

  beyla-recorder:
    image: grafana/beyla:2.1.0
    # Beyla requires to be run in the same process namespace as the process it's watching.
    # In Docker, we can do this by joining the namespace for the watched process with the Beyla
    # container watching it by using a specific `pid` label.
    pid: "service:mythical-recorder"
    # Beyla requires the several system capabilities to run, to add hooks to the underlying kernel.
    # Note that you should *always* be aware of the security implications of adding capabilities
    # before you do so.
    cap_add:
      - SYS_ADMIN
      - SYS_RESOURCE
      - NET_RAW
      - DAC_READ_SEARCH
      - SYS_PTRACE
      - PERFMON
      - BPF
      - CHECKPOINT_RESTORE
    # If using the above capability fails to instrument your service, remove it and uncomment the
    # line below. Beware that this will allow Beyla to run with full privileges, which may be
    # undesirable.
    #privileged: true
    command:
      - /beyla
      - --config=/configs/config.yaml
    volumes:
      - ./beyla/:/configs
    # See the full list of configuration options at
    # https://grafana.com/docs/grafana-cloud/monitor-applications/beyla/configure/options/ for more details on the
    # options set below.
    environment:
      BEYLA_OPEN_PORT: "4002"                                   # Instrument any service listening on port 4002.
      BEYLA_SERVICE_NAMESPACE: "mythical"                       # The namespace for the service.
      BEYLA_PROMETHEUS_PORT: "9090"                             # The port to expose Prometheus metrics on.
      #BEYLA_BPF_TRACK_REQUEST_HEADERS: "true"
      OTEL_SERVICE_NAME: "beyla-mythical-recorder"              # The service name to use for OpenTelemetry traces.
      OTEL_EXPORTER_OTLP_TRACES_INSECURE: "true"                # Whether to use an insecure connection to Grafana Alloy.
      OTEL_EXPORTER_OTLP_PROTOCOL: "grpc"                       # The protocol to use to send traces to Grafana Alloy.
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "http://alloy:4317"   # The endpoint to send traces to.
    # The `depends_on` block below ensures that the mythical-recorder service is started before Beyla.
    depends_on:
      mythical-recorder:
        condition: service_started
